{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. import the modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "import networkx as nx\n",
    "from gtda.diagrams import BettiCurve\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from scipy.stats import rankdata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. load and prep the data\n",
    "\n",
    "Each row of a given file is a graph, with:\n",
    "- edge_index (list: 2 x #edges): pairs of nodes constituting edges\n",
    "- edge_attr (list: #edges x #edge-features): for the aforementioned edges, contains their features\n",
    "- y (list: 1 x #labels): contains the number of labels available to predict (here 1, equal to zero or one)\n",
    "\n",
    "here, each entry in dataset, is a graph AND NOT tabular data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 38], x=[17, 7], edge_attr=[38, 4], y=[1])\n"
     ]
    }
   ],
   "source": [
    "dataset = TUDataset(root=\"data/TUDataset\", name=\"MUTAG\")\n",
    "print (dataset[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. initialize a constructor for simplicial complexes\n",
    "- homology_dimensions decide how many betti vectors we want to compute, for now, we'll stick to Betti-0 and Betti-1\n",
    "- we will also compute distance matrix based on differences in atomic numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VR = VietorisRipsPersistence(metric=\"precomputed\", homology_dimensions=[0,1], n_jobs=-1)\n",
    "\n",
    "# Mapping from MUTAG node labels to atomic numbers\n",
    "# 0=C(6), 1=N(7), 2=O(8), 3=F(9), 4=I(53), 5=Cl(17), 6=Br(79)\n",
    "atomic_number_map = {0: 6, 1: 7, 2: 8, 3: 9, 4: 53, 5: 17, 6: 79}\n",
    "\n",
    "graph_distance_matrices = []\n",
    "y = []\n",
    "for data in dataset:\n",
    "    G = nx.Graph()\n",
    "    edges = data.edge_index.numpy().T\n",
    "    G.add_edges_from(edges)\n",
    "    y.append(data.y.item())\n",
    "\n",
    "    # Get node labels (atomic types) and map to atomic numbers\n",
    "    node_labels = data.x[:, 0].numpy()  # First column contains node labels\n",
    "    atomic_numbers = np.array([atomic_number_map[label] for label in node_labels])\n",
    "\n",
    "    # Create distance matrix based on differences in atomic numbers\n",
    "    dist_matrix = np.abs(atomic_numbers[:, None] - atomic_numbers[None, :])\n",
    "\n",
    "    graph_distance_matrices.append(dist_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. perform persistent homology\n",
    "- convert graphs to filtrations (nested sequence of simplicial complexes)\n",
    "- calculate persistence\n",
    "\n",
    "### computing Betti Vectors and storing them in  a dataframe \n",
    "- betti_features essentially stores a numpy array, where each row corresponds to the betti-0 and betti-1 for each graph\n",
    "- number of intervals/testing spaces in each betti vector is the count of n_bins from min birth to max death\n",
    "- betti vectorization renders fixed set data, that can be converted into tabular form that is needed for a pd datafram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgms = VR.fit_transform(graph_distance_matrices)\n",
    "\n",
    "BC_100 = BettiCurve(n_bins = 100)\n",
    "BC_50 = BettiCurve(n_bins = 50)\n",
    "BC_200 = BettiCurve(n_bins = 200)\n",
    "\n",
    "betti_50 = BC_50.fit_transform(dgms)\n",
    "betti_100 = BC_100.fit_transform(dgms)\n",
    "betti_200 = BC_200.fit_transform(dgms)\n",
    "\n",
    "# betti_features = BC.fit_transform(dgms)\n",
    "\n",
    "X = np.hstack([\n",
    "    betti_50.reshape(len(betti_50), -1),\n",
    "    betti_100.reshape(len(betti_100), -1),\n",
    "    betti_200.reshape(len(betti_200), -1)\n",
    "])\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. hyperparam tuning & training the classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      " {'solver': 'sgd', 'random_state': 0, 'momentum': 0.9, 'max_iter': 300, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (100,), 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(100,), (150,)],\n",
    "    \"activation\": [\"relu\", \"tanh\", \"logistic\"],\n",
    "    \"solver\": [\"sgd\"],\n",
    "    \"random_state\":[0, 42, 20],\n",
    "    \"learning_rate\":[\"adaptive\", \"invscaling\"],\n",
    "    \"max_iter\": [200, 500, 300],\n",
    "    \"momentum\": [0.9, 0.5, 0.3]\n",
    "}\n",
    "\n",
    "clf = MLPClassifier(shuffle= True)\n",
    "search = RandomizedSearchCV(\n",
    "    clf, \n",
    "    param_distributions = param_grid,\n",
    "    n_iter = 5,\n",
    "    cv = 5,\n",
    "    scoring = \"accuracy\",\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "search.fit(X, y)\n",
    "print(\"Best params:\\n\", search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP accuracy:  0.6842105263157895\n",
      "Mean cross validation score:  0.6649122807017545\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),\n",
    "    activation=\"relu\", \n",
    "    momentum = 0.9,\n",
    "    learning_rate = \"invscaling\",\n",
    "    solver=\"sgd\",\n",
    "    random_state=0,\n",
    "    max_iter=300,\n",
    "    #max_fun = 15000,\n",
    "    nesterovs_momentum = True\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(\"MLP accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Mean cross validation score: \", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (gtda_env)",
   "language": "python",
   "name": "gtda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
