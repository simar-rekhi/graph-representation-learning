{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7255863-991c-48fb-9aa3-a48151058648",
   "metadata": {},
   "source": [
    "### 1. import the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc05c48a-fa1b-429e-9779-c11cfd24bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "import networkx as nx\n",
    "from gtda.diagrams import BettiCurve\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from scipy.stats import rankdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c30518-42ba-4b29-8808-75ebab24ab49",
   "metadata": {},
   "source": [
    "### 2. load and prep the data\n",
    "\n",
    "Each row of a given file is a graph, with:\n",
    "- edge_index (list: 2 x #edges): pairs of nodes constituting edges\n",
    "- edge_attr (list: #edges x #edge-features): for the aforementioned edges, contains their features\n",
    "- y (list: 1 x #labels): contains the number of labels available to predict (here 1, equal to zero or one)\n",
    "\n",
    "here, each entry in dataset, is a graph AND NOT tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfdfc911-f677-4d7f-97a5-46ccc14d8eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 38], x=[17, 7], edge_attr=[38, 4], y=[1])\n"
     ]
    }
   ],
   "source": [
    "dataset = TUDataset(root=\"data/TUDataset\", name=\"MUTAG\")\n",
    "print (dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b19314-b647-46bd-a9cf-6be1552b54fa",
   "metadata": {},
   "source": [
    "### 3. initialize a constructor for simplicial complexes\n",
    "- homology_dimensions decide how many betti vectors we want to compute, for now, we'll stick to Betti-0 and Betti-1\n",
    "- we will also compute distance matrix based on differences in degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d529352-8b59-44c0-b4b1-e1efdf579b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VR = VietorisRipsPersistence(metric=\"precomputed\", homology_dimensions=[0,1])\n",
    "\n",
    "graph_distance_matrices = []\n",
    "y = []\n",
    "for data in dataset:\n",
    "    G = nx.Graph()\n",
    "    edges = data.edge_index.numpy().T\n",
    "    G.add_edges_from(edges)\n",
    "    y.append(data.y.item())\n",
    "\n",
    "    # degree dictionary\n",
    "    deg_central_dict = nx.degree_centrality(G)\n",
    "    values = np.array([deg_central_dict[node] for node in G.nodes()])\n",
    "\n",
    "    # converting degree values into ranks\n",
    "    ranks = rankdata(values, method=\"average\")\n",
    "\n",
    "    dist_matrix = np.abs(ranks[:, None]- ranks[None, :])\n",
    "\n",
    "    graph_distance_matrices.append(dist_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47670e85-c591-442e-b5eb-8dcac99292aa",
   "metadata": {},
   "source": [
    "### 4. perform persistent homology\n",
    "- convert graphs to filtrations (nested sequence of simplicial complexes)\n",
    "- calculate persistence\n",
    "\n",
    "### computing Betti Vectors and storing them in  a dataframe \n",
    "- betti_features essentially stores a numpy array, where each row corresponds to the betti-0 and betti-1 for each graph\n",
    "- number of intervals/testing spaces in each betti vector is the count of n_bins from min birth to max death\n",
    "- betti vectorization renders fixed set data, that can be converted into tabular form that is needed for a pd datafram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec836e23-8abc-4f09-8364-b86a079a931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgms = VR.fit_transform(graph_distance_matrices)\n",
    "\n",
    "BC_100 = BettiCurve(n_bins = 100)\n",
    "BC_50 = BettiCurve(n_bins = 50)\n",
    "BC_200 = BettiCurve(n_bins = 200)\n",
    "\n",
    "betti_50 = BC_50.fit_transform(dgms)\n",
    "betti_100 = BC_100.fit_transform(dgms)\n",
    "betti_200 = BC_200.fit_transform(dgms)\n",
    "\n",
    "# betti_features = BC.fit_transform(dgms)\n",
    "\n",
    "X = np.hstack([\n",
    "    betti_50.reshape(len(betti_50), -1),\n",
    "    betti_100.reshape(len(betti_100), -1),\n",
    "    betti_200.reshape(len(betti_200), -1)\n",
    "])\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec53cd09-0ea3-4375-96f8-4c7887dcc002",
   "metadata": {},
   "source": [
    "### 5. hyperparam tuning & training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f6dda87-4ce0-40d3-810a-49b1c43576a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      " {'solver': 'adam', 'max_iter': 500, 'learning_rate_init': 0.01, 'hidden_layer_sizes': (150,), 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(100,), (150,)],\n",
    "    \"activation\": [\"relu\", \"tanh\"],\n",
    "    \"solver\": [\"adam\"],\n",
    "    \"learning_rate_init\": [0.01, 0.05],\n",
    "    \"max_iter\": [500]\n",
    "}\n",
    "\n",
    "clf = MLPClassifier(random_state=42)\n",
    "search = RandomizedSearchCV(\n",
    "    clf, \n",
    "    param_distributions = param_grid,\n",
    "    n_iter = 5,\n",
    "    cv = 5,\n",
    "    scoring = \"accuracy\",\n",
    "    random_state = 42,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "search.fit(X, y)\n",
    "print(\"Best params:\\n\", search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "554a856b-dd28-456f-9c88-1685bd68d481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB accuracy:  0.8947368421052632\n",
      "Mean cross validation score:  0.8453216374269005\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(150,),\n",
    "    activation=\"relu\", \n",
    "    learning_rate_init=0.01, \n",
    "    solver=\"adam\",\n",
    "    random_state=42,\n",
    "    max_iter=500\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "print(\"XGB accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Mean cross validation score: \", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5110044f-b317-4c67-8aaf-aee5d1597fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (gtda_env)",
   "language": "python",
   "name": "gtda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
