{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6bbaabe-1f99-455a-9481-69df8e6c42fc",
   "metadata": {},
   "source": [
    "# PH template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55754a04-92d6-4e6c-960d-d9b485a480a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "import pyflagser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d73b3aa-d181-4f24-bb9c-34d92b5aa17a",
   "metadata": {},
   "source": [
    "## Set Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc9c0201-ee1d-4db3-a133-cc7eac1a5d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r.v. for filtration \n",
    "N_THRESHOLD = 12\n",
    "USE_QTY = True\n",
    "\n",
    "# these are the limits for the PH filtration\n",
    "MIN_DIM = 0\n",
    "MAX_DIM = 2\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9184d887-dbb1-4251-b964-31589423b9df",
   "metadata": {},
   "source": [
    "## Betti Curvature Computation for Active Noted\n",
    "here,\n",
    "- active nodes: are in the form of an iterable node of indices\n",
    "- full_graph is the nx graph of the original\n",
    "- return: betti tuple consolidating (b0, b1, b2) i.e., betti-1, betti-2, betti-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24959b7c-5e47-429f-a113-0aa7c34eba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_betti_curvature(active_nodes, full_graph):\n",
    "    G = full_graph.subgraph(sorted(active_nodes)).copy()\n",
    "\n",
    "    # convert induced subgraph of active nodes into adjacency matrix\n",
    "    nodelist = sorted(G.nodes())\n",
    "\n",
    "    # validatory checks\n",
    "    if len(nodelist) == 0:\n",
    "        return (0,0,0)\n",
    "\n",
    "    adj_mat = nx.to_numpy_array(G, nodelist = nodelist)\n",
    "\n",
    "    # refer to pyflagser\n",
    "    my_flag = pyflagser.flagser_unweighted(\n",
    "        adj_mat, min_dimension= MIN_DIM, max_dimension = MAX_DIM, \n",
    "        directed=False, coeff = 2, approximation=None\n",
    "    )\n",
    "\n",
    "    x = my_flag.get(\"betti\", [])\n",
    "    b0 = int(x[0]) if len(x) > 0 else 0\n",
    "    b1 = int (x[1]) if len(x) > 1 else 0\n",
    "    b2 = int(x[2]) if len(x) > 2 else 0\n",
    "    return (b0, b1, b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307716b3-440d-4761-91af-92d445ee2ce6",
   "metadata": {},
   "source": [
    "### Graph from pyflagser object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a5e2c5c-d86d-4ca2-a9ed-d2049d728e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_from_pyg_data(data):\n",
    "    \"\"\"\n",
    "    Construct a networkx Graph from a PyG data object.\n",
    "    Assumes node features/data.x contain atomic numbers in a known column. \n",
    "    MUTAG commonly stores node labels in data.x or data.z.\n",
    "    We'll attempt common places: data.x (first column), data.z, or data.node_attr if present.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    num_nodes = data.num_nodes\n",
    "\n",
    "    # Add nodes\n",
    "    for i in range(num_nodes):\n",
    "        G.add_node(i)\n",
    "\n",
    "    # Add edges\n",
    "    edge_index = data.edge_index.numpy()\n",
    "    for u, v in edge_index.T:\n",
    "        G.add_edge(int(u), int(v))\n",
    "\n",
    "    # node attributes / atomic number reading heuristics\n",
    "    atomic_numbers = None\n",
    "    if hasattr(data, 'x') and data.x is not None:\n",
    "        x_np = data.x.numpy()\n",
    "        # If single feature per node, use directly\n",
    "        if x_np.ndim == 1 or x_np.shape[1] == 1:\n",
    "            atomic_numbers = x_np.reshape(-1)\n",
    "        else:\n",
    "            # If one-hot encoded, use argmax to get label index\n",
    "            atomic_numbers = np.argmax(x_np, axis=1)\n",
    "\n",
    "    # fallback if atomic numbers in data.z\n",
    "    if atomic_numbers is None and hasattr(data, 'z'):\n",
    "        atomic_numbers = data.z.numpy().reshape(-1)\n",
    "\n",
    "    if atomic_numbers is None:\n",
    "        # default: set all to 0 (should not happen for MUTAG)\n",
    "        atomic_numbers = np.zeros(num_nodes, dtype=float)\n",
    "\n",
    "    # attach atomic numbers as node attributes\n",
    "    for i, val in enumerate(atomic_numbers):\n",
    "        G.nodes[i]['atomic_number'] = float(val)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f47dedd-20da-43d8-9151-c842095c630e",
   "metadata": {},
   "source": [
    "### Thresholds for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "140d3c30-7306-4acf-97b3-931891b905e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_thresholds_for_dataset(all_node_values, n_thresholds=N_THRESHOLD, quantile=USE_QTY):\n",
    "    vals = np.array(all_node_values)\n",
    "    if quantile:\n",
    "        qs = np.linspace(0.0, 1.0, n_thresholds)\n",
    "        thresholds = np.quantile(vals, qs)\n",
    "    else:\n",
    "        thresholds = np.linspace(vals.min(), vals.max(), n_thresholds)\n",
    "    # make unique and sorted\n",
    "    thresholds = np.unique(np.asarray(thresholds))\n",
    "    return thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59eb85bd-ce37-4d3e-85c0-0b046f595d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MUTAG with 188 graphs.\n",
      "Using thresholds: [0. 1. 2. 6.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graphs: 100%|████████████████████████████████████████████████████████████████████████| 188/188 [00:05<00:00, 36.69it/s]\n",
      "C:\\DevTools\\Projects\\topo-ml\\gtda_env\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [23:30:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "Accuracy: 0.7894736842105263\n",
      "Balanced Accuracy: 0.736842105263158\n",
      "ROC AUC: 0.8753462603878116\n",
      "Confusion matrix:\n",
      " [[11  8]\n",
      " [ 4 34]]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load MUTAG\n",
    "    dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n",
    "    print(f\"Loaded MUTAG with {len(dataset)} graphs.\")\n",
    "\n",
    "    graphs = []\n",
    "    labels = []\n",
    "    all_node_values = []\n",
    "\n",
    "    # convert each PyG graph to networkx and record atomic numbers across dataset\n",
    "    for data in dataset:\n",
    "        G = graph_from_pyg_data(data)\n",
    "        graphs.append(G)\n",
    "        labels.append(int(data.y.item()))\n",
    "        # collect node atomic numbers\n",
    "        values = [G.nodes[n].get('atomic_number', 0.0) for n in G.nodes()]\n",
    "        all_node_values.extend(values)\n",
    "\n",
    "    thresholds = build_thresholds_for_dataset(all_node_values, n_thresholds=N_THRESHOLD, quantile=USE_QTY)\n",
    "    print(\"Using thresholds:\", thresholds)\n",
    "\n",
    "    # For each graph, compute betti curves across thresholds\n",
    "    features = []   # each element will be concatenated betti0..2 curves + summary stats\n",
    "    for G in tqdm(graphs, desc=\"Graphs\"):\n",
    "        node_vals = {n: G.nodes[n].get('atomic_number', 0.0) for n in G.nodes()}\n",
    "        betti0_curve = []\n",
    "        betti1_curve = []\n",
    "        betti2_curve = []\n",
    "        for eps in thresholds:\n",
    "            # sublevel: nodes with value <= eps\n",
    "            active_nodes = [n for n, v in node_vals.items() if v <= eps]\n",
    "            b0, b1, b2 = compute_betti_curvature(active_nodes, G)\n",
    "            betti0_curve.append(b0)\n",
    "            betti1_curve.append(b1)\n",
    "            betti2_curve.append(b2)\n",
    "        # vectorize: baseline = concatenated curves + summary stats\n",
    "        feat = []\n",
    "        feat.extend(betti0_curve)\n",
    "        feat.extend(betti1_curve)\n",
    "        feat.extend(betti2_curve)\n",
    "        # add simple summary stats\n",
    "        feat.append(np.mean(betti0_curve))\n",
    "        feat.append(np.max(betti0_curve))\n",
    "        feat.append(np.sum(betti0_curve))\n",
    "        feat.append(np.mean(betti1_curve))\n",
    "        feat.append(np.max(betti1_curve))\n",
    "        feat.append(np.sum(betti1_curve))\n",
    "        feat.append(np.mean(betti2_curve))\n",
    "        feat.append(np.max(betti2_curve))\n",
    "        feat.append(np.sum(betti2_curve))\n",
    "        features.append(np.array(feat, dtype=float))\n",
    "\n",
    "    X = np.vstack(features)\n",
    "    y = np.array(labels)\n",
    "\n",
    "    # train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=RANDOM_STATE)\n",
    "\n",
    "    clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=RANDOM_STATE)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_proba = clf.predict_proba(X_test)[:, 1] if clf.n_classes_ > 1 else clf.predict_proba(X_test)[:, 0]\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    try:\n",
    "        roc = roc_auc_score(y_test, y_proba)\n",
    "    except Exception:\n",
    "        roc = None\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"Results:\")\n",
    "    print(\"Accuracy:\", acc)\n",
    "    print(\"Balanced Accuracy:\", bal_acc)\n",
    "    print(\"ROC AUC:\", roc)\n",
    "    print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eda786-e8cd-4aa4-b8cd-229ad8bd405a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc244de-e9ec-4e89-b751-3a62f0a826d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (gtda_env)",
   "language": "python",
   "name": "gtda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
