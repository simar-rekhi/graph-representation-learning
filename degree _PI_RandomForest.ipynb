{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e15bcef-10be-482b-9fb3-af1d78a3c2ac",
   "metadata": {},
   "source": [
    "### import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca022cf7-933d-4bf1-a697-b81ba2c75a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import PersistenceEntropy, PersistenceImage\n",
    "import gtda\n",
    "print(gtda.__version__)\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc86291-f174-4d68-bc7a-ec6cc45eb316",
   "metadata": {},
   "source": [
    "### step 1: load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd98b30b-1c9a-4029-9aea-3069fd4bbcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n",
    "\n",
    "# extracting the graphs from the dataset\n",
    "graphs = [data for data in dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84225263-17c3-413e-8c5f-494bbe335dce",
   "metadata": {},
   "source": [
    "### step 2: node filtration values\n",
    "\n",
    "- we assign a metric to track each graph, here, we deploy degree\n",
    "- setting up a threshold t and then progressively increasing it. As we do this, we only read/learn from the graphs with degree <= t, and therefore, allow more graphs as t is made to increase.\n",
    "- learning and keeping a track of these graphs progressively is done in the next step - persistent homology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "954a3359-471b-4187-97b1-7b7070e4dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = [nx.Graph() for _ in dataset]\n",
    "\n",
    "for i, g in enumerate(graphs):\n",
    "    g.add_edges_from(dataset[i].edge_index.t().tolist())\n",
    "\n",
    "adj_matrices = [nx.to_numpy_array(g) for g in graphs]\n",
    "\n",
    "# degree_filtration = dict(adj_matrices.degree())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2f156f-81bd-40cf-956a-a30da4ae9541",
   "metadata": {},
   "source": [
    "### step 3: persistent homology pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96c0bb04-5abe-4f06-99d1-409c907d849e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DevTools\\Projects\\topo-ml\\gtda_env\\lib\\site-packages\\gtda\\homology\\simplicial.py:232: DataDimensionalityWarning: All arrays/matrices are square. This is consistent with a collection of distance/adjacency matrices, but the entries will be treated as collections of vectors in Euclidean space.\n",
      "  check_point_clouds(X, accept_sparse=True,\n",
      "C:\\DevTools\\Projects\\topo-ml\\gtda_env\\lib\\site-packages\\gtda\\homology\\simplicial.py:299: DataDimensionalityWarning: All arrays/matrices are square. This is consistent with a collection of distance/adjacency matrices, but the entries will be treated as collections of vectors in Euclidean space.\n",
      "  X = check_point_clouds(X, accept_sparse=True,\n"
     ]
    }
   ],
   "source": [
    "VR = VietorisRipsPersistence(homology_dimensions=[0, 1])\n",
    "diagrams = VR.fit_transform(adj_matrices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78924d45-cad1-48fb-86d7-821e5d378270",
   "metadata": {},
   "source": [
    "### step 4: vectorize persistence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b6c15ee-70c4-4923-ada4-1572f4d012fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "persistence_image = PersistenceImage(n_bins=100, n_jobs=None)\n",
    "X = persistence_image.fit_transform(diagrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c361b8-f623-4ce4-806c-aeb9db7f4a05",
   "metadata": {},
   "source": [
    "### step 5: train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e648f82d-4199-4524-81d0-0038b89e25f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([d.y.item() for d in dataset])   # shape (188,)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.reshape(len(X), -1), y, test_size=0.2)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948a95b0-232b-458b-8166-2a0113ed3ac6",
   "metadata": {},
   "source": [
    "### step 6: analyze accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d500da1b-cd98-4f2e-b6d1-22d1ab6ef674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  89.47368421052632 %\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: \", accuracy_score(y_test, y_pred)*100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (gtda_env)",
   "language": "python",
   "name": "gtda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
